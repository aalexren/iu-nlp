{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 7: Finishing ngrams and Word sense disambiguation with Lesk algorithm\n",
        "\n",
        "```\n",
        "Plan : \n",
        "  1. Ngrams as features, Skip-grams\n",
        "  1. Simplified Lesk algorithm, using WordNet\n",
        "  1. (optional) WSD with Naive Bayes Classifier\n",
        "```"
      ],
      "metadata": {
        "id": "s1yR4nzdCpkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ngrams and skip-grams as features\n",
        "\n",
        "What limitations of Bag-of-Words model do you remember?\n",
        "\n",
        "One of them is a loss of word order. For the following ewo sentences the BoW are identical, however, the labels are different.\n",
        "* No, this movie is good. [ Positive sentiment]\n",
        "* This movie is no good. [ Negative sentiment]\n",
        "\n",
        "So, introducing Ngrams into the Bag-of-Words model (Bag-of-Ngrams) can mitigate this limitation (How?). What else can be done to improve?\n",
        "\n",
        "* This movie is not quite good.\n",
        "* This movie is not that good.\n",
        "* This movie is not very good.\n",
        "\n",
        "Can you see a pattern here? It seems we could add \"not _ good\" instead of all the possible ngrams. Such ngrams are called Skip-grams.\n",
        "\n",
        "**N-grams** are sequences of adjacent units (letters, words, or whatever counting unit you happen to care about) of length \"n\"; it's a cover term for bigrams (sequences of 2 adjacent things, n = 2), trigrams (sequences of three adjacent things), 4-grams, etc.\n",
        "\n",
        "\n",
        "**Skip-grams** (or \"k-skip-n-grams\") are sequences of ordered but not-necessarily-adjacent (thus \"skipped\") units, where the gaps can be at most \"k\" units long.\n",
        "\n",
        "\n",
        "For example, in the sentence \"The quick brown fox jumped over the lazy dog\"\n",
        "* bigrams (2-grams) include \"The quick\", \"quick brown\", \"brown fox\", fox jumped\", \"jumped over\", \"over the\", \"the lazy\", and \"lazy dog\",\n",
        "* 1-skip-2-grams include all of the bigrams in addition to \"the _ brown\", \"quick _ fox\", \"brown _ jumped\", \"fox _ over\", \"jumped _ the\", \"over _ lazy\", and \"the _ dog\"."
      ],
      "metadata": {
        "id": "qSvAiDr_ljzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement a TfIdf Classifier, which will take unigrams, bigram and 1-skip 2-grams as input. Compare it with a similar classifier with only unigrams input.\n",
        "\n",
        "Possible dataset: [IMDB movie reviews](https://huggingface.co/datasets/imdb)"
      ],
      "metadata": {
        "id": "ze1OZjZxsLyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your code here "
      ],
      "metadata": {
        "id": "t_YNUi4Vsk0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simplified Lesk algorithm, using WordNet.\n",
        "\n",
        "NLTK provides an interface to access and explore WordNet."
      ],
      "metadata": {
        "id": "Zch1ZReFCnGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "from nltk.corpus import wordnet \n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlfk5Xy2C0rl",
        "outputId": "71375a42-d616-4726-88ad-0692906db2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can find all synsets that contain a given word's base form, or lemma, using `lemmas(word)`\n",
        "\n",
        "* To match a word, it must be given in its base form \n",
        "\n",
        "Words may be converted automatically to their base forms using **`morphy(word)`**, which takes the word and an optional part-of-speech as arguments, and returns the base form of the given word with the matching PoS (or any, if none given)."
      ],
      "metadata": {
        "id": "WgnMWbvBpQkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lists of synsets and their definitions"
      ],
      "metadata": {
        "id": "9ETE9yanpolb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = wordnet.morphy('interest')\n",
        "for l in wordnet.lemmas(w):\n",
        "  print(l)\n",
        "  print(l.synset().definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8d8kdyTEUMh",
        "outputId": "6a63cd28-2f57-41f3-e6fb-5323f61ff966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma('interest.n.01.interest')\n",
            "a sense of concern with and curiosity about someone or something\n",
            "Lemma('sake.n.01.interest')\n",
            "a reason for wanting something done\n",
            "Lemma('interest.n.03.interest')\n",
            "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
            "Lemma('interest.n.04.interest')\n",
            "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
            "Lemma('interest.n.05.interest')\n",
            "(law) a right or legal share of something; a financial involvement with something\n",
            "Lemma('interest.n.06.interest')\n",
            "(usually plural) a social group whose members control some field of activity and who have common aims\n",
            "Lemma('pastime.n.01.interest')\n",
            "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
            "Lemma('interest.v.01.interest')\n",
            "excite the curiosity of; engage the interest of\n",
            "Lemma('concern.v.02.interest')\n",
            "be on the mind of\n",
            "Lemma('matter_to.v.01.interest')\n",
            "be of importance or consequence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simplified Lesk\n",
        "\n",
        "The Simplified Lesk chooses the word sense which has the most in common between: its dictionary definition and examples, and the context of the target word.\n",
        "\n",
        "For example, if we are interested in identifying the correct sense of the word **`interest`** in the following context:\n",
        "\n",
        "```\n",
        "While some in the United States cheered the election victory of Democrat Barack Obama, on the other side of the world, \n",
        "Chinese showed concern and interest over the state of the economy.\n",
        "```\n",
        "\n",
        "Choose sense with best matches <br>\n",
        "**NB**: ignore stopwords"
      ],
      "metadata": {
        "id": "thXDPlKSqI3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = set(['concern', 'over', 'state','economy'])\n",
        "w_of_int = 'interest'\n",
        "\n",
        "sysnsets = wordnet.synsets(w_of_int)"
      ],
      "metadata": {
        "id": "jn1XKc3oeDUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "sent = 'While some in the United States cheered the election victory of Democrat Barack Obama, on the other side of the world, Chinese showed concern and interest over the state of the economy.'\n",
        "ambiguous = 'interest'\n",
        "print(lesk(sent.split(), ambiguous,'n'))\n",
        "lesk(sent.split(), ambiguous).definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "4_Ij5ve4jOVt",
        "outputId": "47fba0fd-92eb-4f94-de34-4276f5123075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('interest.n.06')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'excite the curiosity of; engage the interest of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO : Write your code here and test it with the example sentence above"
      ],
      "metadata": {
        "id": "HQxVaUqFGhS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "```\n",
        "1. Run your algorithm over the 300 Senseval example sentences.\n",
        "\n",
        "2. Test accuracy using Senseval-2 corpus\n",
        " - Can be installed in NLTK The tags are a little different:\n",
        "      HARD1 corresponds to difficult.a.01 \n",
        "      HARD2 corresponds to hard.a.02 \n",
        "      HARD3 corresponds to hard.a.03.hard\n",
        "  - but the order is the same\n",
        "\n",
        "* Remember to exclude stop words\n",
        "\n",
        "3. Does this algorithm perform better than simply selecting the most common sense for all examples?\n",
        "```"
      ],
      "metadata": {
        "id": "X12DDlbyxMtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Senseval Data"
      ],
      "metadata": {
        "id": "rnDAdKOE6Hbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import senseval as se\n",
        "nltk.download('senseval')\n",
        "se.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJYpQbBDyaY5",
        "outputId": "e3d70dbd-8bd0-4958-9e2f-6fa7d8cba699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]   Package senseval is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hard.pos', 'interest.pos', 'line.pos', 'serve.pos']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from Senseval\n",
        "se.instances()[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3an4-dK4mwC",
        "outputId": "67647859-1dd5-4e07-e966-93f1c3198e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SensevalInstance(word='hard-a', position=20, context=[('``', '``'), ('he', 'PRP'), ('may', 'MD'), ('lose', 'VB'), ('all', 'DT'), ('popular', 'JJ'), ('support', 'NN'), (',', ','), ('but', 'CC'), ('someone', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('kill', 'VB'), ('him', 'PRP'), ('to', 'TO'), ('defeat', 'VB'), ('him', 'PRP'), ('and', 'CC'), ('that', 'DT'), (\"'s\", 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('.', '.'), (\"''\", \"''\")], senses=('HARD1',)),\n",
              " SensevalInstance(word='hard-a', position=10, context=[('clever', 'NNP'), ('white', 'NNP'), ('house', 'NNP'), ('``', '``'), ('spin', 'VB'), ('doctors', 'NNS'), (\"''\", \"''\"), ('are', 'VBP'), ('having', 'VBG'), ('a', 'DT'), ('hard', 'JJ'), ('time', 'NN'), ('helping', 'VBG'), ('president', 'NNP'), ('bush', 'NNP'), ('explain', 'VB'), ('away', 'RB'), ('the', 'DT'), ('economic', 'JJ'), ('bashing', 'NN'), ('that', 'IN'), ('low-and', 'JJ'), ('middle-income', 'JJ'), ('workers', 'NNS'), ('are', 'VBP'), ('taking', 'VBG'), ('these', 'DT'), ('days', 'NNS'), ('.', '.')], senses=('HARD1',)),\n",
              " SensevalInstance(word='hard-a', position=3, context=[('i', 'PRP'), ('find', 'VBP'), ('it', 'PRP'), ('hard', 'JJ'), ('to', 'TO'), ('believe', 'VB'), ('that', 'IN'), ('the', 'DT'), ('sacramento', 'NNP'), ('river', 'NNP'), ('will', 'MD'), ('ever', 'RB'), ('be', 'VB'), ('quite', 'RB'), ('the', 'DT'), ('same', 'JJ'), (',', ','), ('although', 'IN'), ('i', 'PRP'), ('certainly', 'RB'), ('wish', 'VBP'), ('that', 'IN'), ('i', 'PRP'), (\"'m\", 'VBP'), ('wrong', 'JJ'), ('.', '.')], senses=('HARD1',)),\n",
              " SensevalInstance(word='hard-a', position=15, context=[('now', 'RB'), ('when', 'WRB'), ('you', 'PRP'), ('get', 'VBP'), ('bad', 'JJ'), ('credit', 'NN'), ('data', 'NNS'), ('or', 'CC'), ('are', 'VBP'), ('confused', 'VBN'), ('with', 'IN'), ('another', 'DT'), ('person', 'NN'), (',', ','), ('the', 'DT'), ('hard', 'JJ'), ('part', 'NN'), ('in', 'IN'), ('correcting', 'VBG'), ('the', 'DT'), ('mistake', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('even', 'RB'), ('knowing', 'VBG'), ('where', 'WRB'), ('it', 'PRP'), ('is', 'VBZ'), ('recorded', 'VBN'), (',', ','), ('let', 'VB'), ('alone', 'RB'), ('having', 'VBG'), ('access', 'NN'), ('.', '.')], senses=('HARD1',)),\n",
              " SensevalInstance(word='hard-a', position=66, context=[(\"'a\", 'NN'), ('great', 'JJ'), ('share', 'NN'), ('of', 'IN'), ('responsibility', 'NN'), ('for', 'IN'), ('this', 'DT'), ('national', 'JJ'), ('tragedy', 'NN'), ('unquestionably', 'RB'), ('lies', 'VBZ'), ('with', 'IN'), ('the', 'DT'), ('president', 'NN'), ('of', 'IN'), ('the', 'DT'), ('country', 'NN'), ('.', '.'), (\"'\", \"''\"), ('--', ':'), ('eduard', 'NNP'), ('shevardnadze', 'NNP'), (',', ','), ('former', 'JJ'), ('foreign', 'JJ'), ('minister', 'NN'), (';', ':'), (\"'we\", 'PRP'), ('are', 'VBP'), ('so', 'RB'), ('deep', 'JJ'), ('in', 'IN'), ('this', 'DT'), ('crisis', 'NN'), ('that', 'IN'), ('all', 'PDT'), ('this', 'DT'), ('business', 'NN'), ('about', 'IN'), ('leaving', 'VBG'), ('the', 'DT'), ('party', 'NN'), (',', ','), ('not', 'RB'), ('leaving', 'VBG'), ('the', 'DT'), ('party', 'NN'), ('--', ':'), ('that', 'WDT'), ('will', 'MD'), ('never', 'RB'), ('get', 'VB'), ('us', 'PRP'), ('out', 'IN'), ('.', '.'), (\"'\", \"''\"), ('--', ':'), ('natasha', 'NNP'), (',', ','), ('a', 'DT'), ('moscow', 'NNP'), ('bookkeeper', 'NN'), (';', ':'), (\"'our\", 'NN'), ('life', 'NN'), ('is', 'VBZ'), ('harder', 'JJ'), ('now', 'RB'), (',', ','), ('yes', 'UH'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('is', 'VBZ'), ('better', 'JJR'), ('to', 'TO'), ('be', 'VB'), ('hungry', 'JJ'), ('and', 'CC'), ('free', 'JJ'), ('.', '.'), (\"'\", \"''\"), ('--', ':'), ('lena', 'NNP'), ('sedykh', 'NNP'), (',', ','), ('a', 'DT'), ('moscow', 'NNP'), ('street', 'NN'), ('sweeper', 'NN'), (';', ':'), (\"'if\", 'NN'), ('you', 'PRP'), ('judge', 'VBP'), ('by', 'IN'), ('astrology', 'NN'), (',', ','), ('gorbachev', 'NNP'), ('is', 'VBZ'), ('cancer', 'NNP'), (',', ','), ('and', 'CC'), ('yeltsin', 'NNP'), ('and', 'CC'), ('russia', 'NNP'), ('are', 'VBP'), ('aquarius', 'NNP'), ('.', '.')], senses=('HARD1',))]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = wordnet.morphy('hard')\n",
        "for l in wordnet.lemmas(w):\n",
        "  print(l)\n",
        "  print(l.synset().definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0miAEP7Q3lyR",
        "outputId": "ecded76f-c052-4e3c-d7c6-2303894f3e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma('difficult.a.01.hard')\n",
            "not easy; requiring great physical or mental effort to accomplish or comprehend or endure\n",
            "Lemma('hard.a.02.hard')\n",
            "dispassionate; \n",
            "Lemma('hard.a.03.hard')\n",
            "resisting weight or pressure\n",
            "Lemma('hard.s.04.hard')\n",
            "very strong or vigorous\n",
            "Lemma('arduous.s.01.hard')\n",
            "characterized by effort to the point of exhaustion; especially physical effort\n",
            "Lemma('unvoiced.a.01.hard')\n",
            "produced without vibration of the vocal cords\n",
            "Lemma('hard.a.07.hard')\n",
            "(of light) transmitted directly from a pointed light source\n",
            "Lemma('hard.a.08.hard')\n",
            "(of speech sounds); produced with the back of the tongue raised toward or touching the velum\n",
            "Lemma('intemperate.s.03.hard')\n",
            "given to excessive indulgence of bodily appetites especially for intoxicating liquors\n",
            "Lemma('hard.s.10.hard')\n",
            "being distilled rather than fermented; having a high alcoholic content\n",
            "Lemma('hard.s.11.hard')\n",
            "unfortunate or hard to bear\n",
            "Lemma('hard.s.12.hard')\n",
            "dried out\n",
            "Lemma('hard.r.01.hard')\n",
            "with effort or force or vigor\n",
            "Lemma('hard.r.02.hard')\n",
            "with firmness\n",
            "Lemma('hard.r.03.hard')\n",
            "earnestly or intently\n",
            "Lemma('hard.r.04.hard')\n",
            "causing great damage or hardship\n",
            "Lemma('hard.r.05.hard')\n",
            "slowly and with difficulty\n",
            "Lemma('heavily.r.07.hard')\n",
            "indulging excessively\n",
            "Lemma('hard.r.07.hard')\n",
            "into a solid condition\n",
            "Lemma('hard.r.08.hard')\n",
            "very near or close in space or time\n",
            "Lemma('hard.r.09.hard')\n",
            "with pain or distress or bitterness\n",
            "Lemma('hard.r.10.hard')\n",
            "to the full extent possible; all the way\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = wordnet.morphy('serve')\n",
        "for l in wordnet.lemmas(w):\n",
        "  print(l)\n",
        "  print(l.synset().definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JARKD_v49T5",
        "outputId": "6733da6b-7900-4859-944a-5ce1859ad9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma('serve.n.01.serve')\n",
            "(sports) a stroke that puts the ball in play\n",
            "Lemma('serve.v.01.serve')\n",
            "serve a purpose, role, or function\n",
            "Lemma('serve.v.02.serve')\n",
            "do duty or hold offices; serve in a specific function\n",
            "Lemma('serve.v.03.serve')\n",
            "contribute or conduce to\n",
            "Lemma('service.v.01.serve')\n",
            "be used by; as of a utility\n",
            "Lemma('serve.v.05.serve')\n",
            "help to some food; help with food or drink\n",
            "Lemma('serve.v.06.serve')\n",
            "provide (usually but not necessarily food)\n",
            "Lemma('serve.v.07.serve')\n",
            "devote (part of) one's life or efforts to, as of countries, institutions, or ideas\n",
            "Lemma('serve.v.08.serve')\n",
            "promote, benefit, or be useful or beneficial to\n",
            "Lemma('serve.v.09.serve')\n",
            "spend time in prison or in a labor camp\n",
            "Lemma('serve.v.10.serve')\n",
            "work for or be a servant to\n",
            "Lemma('serve.v.11.serve')\n",
            "deliver a warrant or summons to someone\n",
            "Lemma('suffice.v.01.serve')\n",
            "be sufficient; be adequate, either in quality or quantity\n",
            "Lemma('serve.v.13.serve')\n",
            "do military service\n",
            "Lemma('serve.v.14.serve')\n",
            "mate with\n",
            "Lemma('serve.v.15.serve')\n",
            "put the ball into play\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your code here "
      ],
      "metadata": {
        "id": "yYeCDIOL6Yw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1. [Creating text features with bag-of-words, n-grams, parts-of-speach and more](https://uc-r.github.io/creating-text-features)\n",
        "1. [Speech and Language Processing. Daniel Jurafsky & James H. Martin.](https://web.stanford.edu/~jurafsky/slp3/18.pdf)"
      ],
      "metadata": {
        "id": "UTR5OoENC1ys"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fTq3-vsnH-eN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}